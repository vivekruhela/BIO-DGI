{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "import itertools\n",
    "import math\n",
    "# from scipy.stats import ranksums\n",
    "# from collections import Counter\n",
    "import glob\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top500genes = open(\"/home/vivek/jupyter_notebooks/bio_dgi_extension/ppi_string_merged/new_model4/best_performing_model/top_500_genes.txt\").read().split(\"\\n\")\n",
    "top500genes = [i.split(\"\\t\")[0] for i in top500genes]\n",
    "gene798 = open(\"/home/vivek/jupyter_notebooks/bio_dgi_extension/all_genes_798.txt\").read().split('\\n')\n",
    "gene798 = [i for i in gene798 if i]\n",
    "gene34 = open(\"/home/vivek/jupyter_notebooks/bio_dgi_extension/farcastbio/genelist77_mm_mgus.txt\").read().split(\"\\n\")\n",
    "gene34 = [i for i in gene34 if i]\n",
    "gene77 = open(\"/home/vivek/jupyter_notebooks/bio_dgi_extension/farcastbio/77genelist.txt\").read().split(\"\\n\")\n",
    "gene77 = [i for i in gene77 if i]\n",
    "\n",
    "mmrf_sample_list = open('/home/vivek/mmrf_data/mmrf_variant_callers/mmrf_mm_sample_list.txt').read().split('\\n')\n",
    "mmrf_sample_list = [x for x in mmrf_sample_list if x != '']\n",
    "mmrf_sample_list = [i for i in mmrf_sample_list if not \"PB\" in i]\n",
    "aiims_mm_sample_list = open('/home/vivek/aiims_data_processing/scripts/mm_list.txt').read().split('\\n')\n",
    "aiims_mm_sample_list = [x for x in aiims_mm_sample_list if x != '']\n",
    "aiims_mgus_sample_list = open('/home/vivek/aiims_data_processing/scripts/mgus_list.txt').read().split('\\n')\n",
    "aiims_mgus_sample_list = [x for x in aiims_mgus_sample_list if x != '']\n",
    "ega_sample_list = open('/home/vivek/ega_data_1901/scripts/ega_mgus_list.txt').read().split('\\n')\n",
    "ega_sample_list = [x for x in ega_sample_list if x != '']\n",
    "all_mm = list(set(mmrf_sample_list + aiims_mm_sample_list))\n",
    "all_mgus = list(set(aiims_mgus_sample_list + ega_sample_list))\n",
    "# all_mm = [i for i in all_mm if not \"_2_BM_\" in i]\n",
    "# all_mm = [i for i in all_mm if not \"_3_BM_\" in i]\n",
    "# all_mm = [i for i in all_mm if not \"_4_BM_\" in i]\n",
    "\n",
    "mmrf_muse_path = \"/home/vivek/mmrf_data/mmrf_variant_callers/hg19/muse/annovar/vcf_with_AF/vcf_reheader/fathmm/filtered_vcf/\"\n",
    "mmrf_mutect_path = \"/home/vivek/mmrf_data/mmrf_variant_callers/hg19/mutect2/annovar/vcf_reheader/fathmm/filtered_vcf\"\n",
    "mmrf_sniper_path = \"/home/vivek/mmrf_data/mmrf_variant_callers/hg19/somatic_sniper/annovar/vcf_with_AF/vcf_reheader/fathmm/filtered_vcf\"\n",
    "mmrf_varscan_path = \"/home/vivek/mmrf_data/mmrf_variant_callers/hg19/varscan2/annovar/vcf_reheader/fathmm/filtered_vcf\"\n",
    "\n",
    "ega_muse_path = \"/home/vivek/ega_data_1901/muse/fathmm_filtered/filtered_vcf\"\n",
    "ega_mutect_path = \"/home/vivek/ega_data_1901/MUTECT2_analysis/fathmm_filtered/filtered_vcf\"\n",
    "ega_sniper_path = \"/home/vivek/ega_data_1901/SNIPER_analysis/fathmm_filtered/filtered_vcf\"\n",
    "ega_varscan_path = \"/home/vivek/ega_data_1901/varscan2/fathmm_filtered/filtered_vcf\"\n",
    "\n",
    "aiims_mm_muse_path = \"/home/vivek/aiims_data_processing/muse/mm_sample_analysis/fathmm_filtered/filtered_vcf\"\n",
    "aiims_mm_mutect_path = \"/home/vivek/aiims_data_processing/MUTECT2/mm_sample_analysis/fathmm_filtered/filtered_vcf\"\n",
    "aiims_mm_sniper_path = \"/home/vivek/aiims_data_processing/SNIPER/mm_sample_analysis/fathmm_filtered/filtered_vcf\"\n",
    "aiims_mm_varscan_path = \"/home/vivek/aiims_data_processing/varscan2/mm_annovar/vcf_reheader/fathmm/filtered_vcf\"\n",
    "\n",
    "aiims_mgus_muse_path = \"/home/vivek/aiims_data_processing/muse/mgus_sample_analysis/fathmm_filtered/filtered_vcf\"\n",
    "aiims_mgus_mutect_path = \"/home/vivek/aiims_data_processing/MUTECT2/mgus_sample_analysis/fathmm_filtered/filtered_vcf\"\n",
    "aiims_mgus_sniper_path = \"/home/vivek/aiims_data_processing/SNIPER/mgus_sample_analysis/fathmm_filtered/filtered_vcf\"\n",
    "aiims_mgus_varscan_path = \"/home/vivek/aiims_data_processing/varscan2/mgus_annovar/vcf_reheader/fathmm/filtered_vcf\"\n",
    "\n",
    "gene_variants = pd.read_excel(\"/home/vivek/jupyter_notebooks/bio_dgi_extension/final_compilation_work/lof/lof798_ghis.xlsx\")\n",
    "\n",
    "aiims_mgus_cnv_path = \"/home/vivek/aiims_data_processing/cnvkit_analysis/mgus\"\n",
    "aiims_mm_cnv_path = \"/home/vivek/aiims_data_processing/cnvkit_analysis/mm\"\n",
    "ega_cnv_path = \"/home/vivek/ega_data_1901/cnvkit_analysis\"\n",
    "mmrf_cnv_path = \"/home/vivek/mmrf_data/cnv_analysis/filtered_cns\"\n",
    "\n",
    "# with open('/home/vivek/jupyter_notebooks/bio_dgi_extension/cnv_analysis/mm_dict.pkl', 'rb') as f:\n",
    "#     mm_cnv_data = pickle.load(f)\n",
    "    \n",
    "# with open('/home/vivek/jupyter_notebooks/bio_dgi_extension/cnv_analysis/mgus_dict.pkl', 'rb') as f:\n",
    "#     mgus_cnv_data = pickle.load(f)\n",
    "    \n",
    "gene_katz_centrality = pd.read_excel(\"../gene_centrality/katz_centrality.xlsx\", index_col=0)\n",
    "\n",
    "antigen_pathway = open('/home/vivek/jupyter_notebooks/bio_dgi_extension/farcastbio/five_pathways/antigen presentation pathway.txt').read().split('\\n')\n",
    "antigen_pathway = [x for x in antigen_pathway if x != '']\n",
    "cyto_pathway = open('/home/vivek/jupyter_notebooks/bio_dgi_extension/farcastbio/five_pathways/cytoskeleton-rearrangement-genes.txt').read().split('\\n')\n",
    "cyto_pathway = [x for x in cyto_pathway if x != '']\n",
    "histone_pathway = open(\"/home/vivek/jupyter_notebooks/bio_dgi_extension/farcastbio/five_pathways/histone-modification-genes.txt\").read().split('\\n')\n",
    "histone_pathway = [x for x in histone_pathway if x != '']\n",
    "myeloid_pathway = open('/home/vivek/jupyter_notebooks/bio_dgi_extension/farcastbio/five_pathways/myeloid-checkpoints-genes.txt').read().split('\\n')\n",
    "myelois_pathway = [x for x in myeloid_pathway if x != '']\n",
    "nk_pathway = open('/home/vivek/jupyter_notebooks/bio_dgi_extension/farcastbio/five_pathways/NK-Cell Pathway Genes.txt').read().split('\\n')\n",
    "nk_pathway = [x for x in nk_pathway if x != '']\n",
    "\n",
    "driver_list1 = pd.read_csv('/home/vivek/driverGenes_Oncogene_TSG/IntOGen-DriverGenes_MM.tsv', sep = '\\t', index_col = 0).index.tolist()\n",
    "driver_list1 = [i.replace(' ','') for i in driver_list1]\n",
    "driver_list1 = [i for i in driver_list1 if i]\n",
    "driver_list2 = open('/home/vivek/driverGenes_Oncogene_TSG/list_of_63_driver_genes.txt').read().split('\\n')\n",
    "driver_list2 = [i.replace(' ','') for i in driver_list2]\n",
    "driver_list2 = [i for i in driver_list2 if i]\n",
    "driver_list3 = open('/home/vivek/driverGenes_Oncogene_TSG/Genomic_landscape_and_chronological_reconstruction_of_driver_events_in_multiple.txt').read().split('\\n')\n",
    "driver_list3 = [i.replace(' ','') for i in driver_list3]\n",
    "driver_list3 = [i for i in driver_list3 if i]\n",
    "driver_list4 = open(\"/home/vivek/driverGenes_Oncogene_TSG/driver_literature/heterogeneity_of_genomic_evolution_and_mutational_profiles_mm.txt\").read().split('\\n')\n",
    "driver_list4 = [i.replace(' ','') for i in driver_list4]\n",
    "driver_list4 = [i for i in driver_list4 if i]\n",
    "driver_list5 = open(\"/home/vivek/driverGenes_Oncogene_TSG/driver_literature/revealing_impact_of_sv.txt\").read().split('\\n')\n",
    "driver_list5 = [i.replace(' ','') for i in driver_list5]\n",
    "driver_list5 = [i for i in driver_list5 if i]\n",
    "driver_list6 = open(\"/home/vivek/driverGenes_Oncogene_TSG/driver_literature/role_of_aid.txt\").read().split('\\n')\n",
    "driver_list6 = [i.replace(' ','') for i in driver_list6]\n",
    "driver_list6 = [i for i in driver_list6 if i]\n",
    "driver_list7 = open(\"/home/vivek/driverGenes_Oncogene_TSG/driver_literature/wgs_of_mm_reveals_oncogenic_pathways_are_targeted.txt\").read().split('\\n')\n",
    "driver_list7 = [i.replace(' ','') for i in driver_list7]\n",
    "driver_list7 = [i for i in driver_list7 if i]\n",
    "driver_list = list(set(driver_list1 + driver_list2 + driver_list3 + driver_list4 + driver_list5 + driver_list6 + driver_list7))\n",
    "\n",
    "mm_unique_genes = open(\"../../mm_798.txt\").read().split(\"\\n\")\n",
    "mm_unique_genes = [i for i in mm_unique_genes if i]\n",
    "mgus_unique_genes = open(\"../../mgus_798.txt\").read().split(\"\\n\")\n",
    "mgus_unique_genes = [i for i in mgus_unique_genes if i]\n",
    "\n",
    "\"\"\"\n",
    "    Gene Categories:\n",
    "    ----------------\n",
    "    Category-A: Gene that are significantly altered in MM and not in MGUS. [Transformative genes]\n",
    "    Category-B: Gene that are significantly altered in MGUS and not in MM. [Rejected genes]\n",
    "    Category-C: Gene that are significantly altered in both MM and MGUS. [disease initiating genes]\n",
    "\"\"\"\n",
    "\n",
    "cat_a = [i for i in mm_unique_genes if i not in mgus_unique_genes]\n",
    "cat_b = [i for i in mgus_unique_genes if i not in mm_unique_genes]\n",
    "cat_c = [i for i in mgus_unique_genes if i in mm_unique_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_centrality(gen_name):\n",
    "    try:\n",
    "        centrality_score = gene_katz_centrality[gene_katz_centrality.index == gen_name]['katz_centrality'].values[0]\n",
    "        comm = gene_katz_centrality[gene_katz_centrality.index == gen_name]['community'].values[0]\n",
    "        # return '/'.join([str(comm), str(centrality_score)])\n",
    "        return centrality_score, comm\n",
    "    except:\n",
    "        return np.nan, np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_df(sampleid, disease, gene_name):\n",
    "    \n",
    "    if \"MMRF\" in sampleid:\n",
    "        df_muse = pd.read_csv(os.path.join(mmrf_muse_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "        df_mutect = pd.read_csv(os.path.join(mmrf_mutect_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "        df_sniper = pd.read_csv(os.path.join(mmrf_sniper_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "        df_varscan = pd.read_csv(os.path.join(mmrf_varscan_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "        df = pd.concat([df_muse, df_mutect, df_sniper, df_varscan])\n",
    "        df = df[df[\"Gene_refGene\"] == gene_name]\n",
    "        df = df.drop_duplicates(ignore_index=True)\n",
    "        \n",
    "    if \"CR\" in sampleid:\n",
    "        df_muse = pd.read_csv(os.path.join(ega_muse_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "        df_mutect = pd.read_csv(os.path.join(ega_mutect_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "        df_sniper = pd.read_csv(os.path.join(ega_sniper_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "        df_varscan = pd.read_csv(os.path.join(ega_varscan_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "        df = pd.concat([df_muse, df_mutect, df_sniper, df_varscan])\n",
    "        df = df[df[\"Gene_refGene\"] == gene_name]\n",
    "        df = df.drop_duplicates()    \n",
    "    \n",
    "    if \"SM\" in sampleid:\n",
    "        if disease == \"mm\":\n",
    "            df_muse = pd.read_csv(os.path.join(aiims_mm_muse_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "            df_mutect = pd.read_csv(os.path.join(aiims_mm_mutect_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "            df_sniper = pd.read_csv(os.path.join(aiims_mm_sniper_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "            df_varscan = pd.read_csv(os.path.join(aiims_mm_varscan_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "            df = pd.concat([df_muse, df_mutect, df_sniper, df_varscan])\n",
    "            df = df[df[\"Gene_refGene\"] == gene_name]\n",
    "            df = df.drop_duplicates()\n",
    "        elif disease == \"mgus\":\n",
    "            df_muse = pd.read_csv(os.path.join(aiims_mgus_muse_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "            df_mutect = pd.read_csv(os.path.join(aiims_mgus_mutect_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "            df_sniper = pd.read_csv(os.path.join(aiims_mgus_sniper_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "            df_varscan = pd.read_csv(os.path.join(aiims_mgus_varscan_path, sampleid + \".vcf\"), sep=\"\\t\")\n",
    "            df = pd.concat([df_muse, df_mutect, df_sniper, df_varscan])\n",
    "            df = df[df[\"Gene_refGene\"] == gene_name]\n",
    "            df = df.drop_duplicates()\n",
    "        \n",
    "    df['sample_id'] = [sampleid for i in range(len(df))]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_gene_snvs_all_samples(gene_name, disease):\n",
    "    \n",
    "    mm_sample_count, mgus_sample_count = 0,0\n",
    "    mm_samplelevel_count, mgus_samplelevel_count = [], []\n",
    "    if disease == \"mm\":\n",
    "        for sam in all_mm:\n",
    "            df = get_gene_df(sam, \"mm\", gene_name)\n",
    "            mm_samplelevel_count.append(df.shape[0])\n",
    "            mm_sample_count += 1 if df.shape[0] > 0 else 0        \n",
    "        \n",
    "        return mm_sample_count, mm_samplelevel_count\n",
    "        \n",
    "    elif disease == \"mgus\":\n",
    "        for sam in all_mgus:\n",
    "            df = get_gene_df(sam, \"mgus\", gene_name)\n",
    "            mgus_samplelevel_count.append(df.shape[0])\n",
    "            mgus_sample_count += 1 if df.shape[0] > 0 else 0        \n",
    "        \n",
    "        return mgus_sample_count, mgus_samplelevel_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_mm[0][:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genes(cnr_df):\n",
    "    genelist = [i.split(',') if ',' in i else [i] for i in cnr_df[\"gene\"].values.tolist() if not \"Antitarget\" in i]\n",
    "    genelist = sorted(list(set(list(itertools.chain.from_iterable(genelist)))))\n",
    "    genelist = [i for i in genelist if not i == '-']\n",
    "    return genelist\n",
    "\n",
    "def read_sam_cnvs(sam, disease):\n",
    "    if disease == \"mgus\":\n",
    "        if 'SM' in sam:\n",
    "            df = pd.read_csv(os.path.join(aiims_mgus_cnv_path, sam, sam+\"BM_tumor.call.cns\"), sep=\"\\t\")\n",
    "            df = df[df[\"cn\"]!= 2]\n",
    "            df = df[df[\"gene\"] != '-']\n",
    "            df = df[~df[\"chromosome\"].str.contains(\"random\")]\n",
    "            df = df[~df[\"chromosome\"].str.contains(\"hap\")]\n",
    "            df = df[~df[\"chromosome\"].str.contains(\"chrUn\")].reset_index(drop=True)\n",
    "        elif \"CR\" in sam:\n",
    "            df = pd.read_csv(os.path.join(ega_cnv_path, sam, sam+\"-BM_dedup.realigned.call.cns\"), sep=\"\\t\")\n",
    "            df = df[df[\"cn\"]!= 2]\n",
    "            df = df[df[\"gene\"] != '-']\n",
    "            df = df[~df[\"chromosome\"].str.contains('GL')].reset_index(drop=True)\n",
    "    elif disease == \"mm\":\n",
    "        if 'SM' in sam:\n",
    "            df = pd.read_csv(os.path.join(aiims_mm_cnv_path, sam, sam+\"BM_tumor.call.cns\"), sep=\"\\t\")\n",
    "            df = df[df[\"cn\"]!= 2]\n",
    "            df = df[df[\"gene\"] != '-']\n",
    "            df = df[~df[\"chromosome\"].str.contains(\"random\")]\n",
    "            df = df[~df[\"chromosome\"].str.contains(\"hap\")]\n",
    "            df = df[~df[\"chromosome\"].str.contains(\"chrUn\")].reset_index(drop=True)\n",
    "        if \"MMRF\" in sam:\n",
    "            df = pd.read_csv(os.path.join(mmrf_cnv_path, sam[:11]+\"_BM.cns\"), sep=\"\\t\")            \n",
    "            \n",
    "    df['sample'] = [sam for i in range(df.shape[0])]\n",
    "    return df\n",
    "\n",
    "def filter_sam_cnvs(sam_df, gen):\n",
    "    gene_idx = []\n",
    "    for idx in range(sam_df.shape[0]):\n",
    "        try:\n",
    "            string = sam_df.iloc[idx][\"gene\"]\n",
    "            genes = sorted(list(set(ast.literal_eval(string))))\n",
    "        except:\n",
    "            genes = sorted(list(set(sam_df.iloc[idx][\"gene\"].split(','))))\n",
    "        \n",
    "        if gen in genes:\n",
    "            gene_idx.append(idx)\n",
    "    \n",
    "    return sam_df.iloc[gene_idx]\n",
    "\n",
    "# def all_samp_gene_cnv(gene_name, disease):\n",
    "#     df_gene_cnv = pd.DataFrame()\n",
    "#     if disease == \"mm\":\n",
    "#         for k,v in mm_cnv_data['gene_per_sample_dict'].items():\n",
    "#             if gene_name in v:\n",
    "#                 # read sample CNVs\n",
    "#                 df = read_sam_cnvs(k, disease)\n",
    "#                 # Filter CNV for a given gene\n",
    "#                 df = filter_sam_cnvs(df, gene_name)\n",
    "#                 df_gene_cnv = pd.concat([df_gene_cnv, df]).reset_index(drop=True)\n",
    "#     elif disease == \"mgus\":\n",
    "#         for k,v in mgus_cnv_data['gene_per_sample_dict'].items():\n",
    "#             if gene_name in v:\n",
    "#                 # read sample CNVs\n",
    "#                 df = read_sam_cnvs(k, disease)\n",
    "#                 # Filter CNV for a given gene\n",
    "#                 df = filter_sam_cnvs(df, gene_name)\n",
    "#                 df_gene_cnv = pd.concat([df_gene_cnv, df]).reset_index(drop=True)\n",
    "            \n",
    "#     no_sample = len(df_gene_cnv[\"sample\"].unique()) if df_gene_cnv.shape[0] > 0 else 0\n",
    "#     return df_gene_cnv, no_sample\n",
    "\n",
    "\n",
    "def all_samp_gene_cnv(gene_name, disease):\n",
    "    df_gene_cnv = pd.DataFrame()\n",
    "    if disease == \"mm\":\n",
    "        for sam in all_mm:\n",
    "            try:\n",
    "                # read sample CNVs\n",
    "                df = read_sam_cnvs(sam, disease)\n",
    "                # Filter CNV for a given gene\n",
    "                df = filter_sam_cnvs(df, gene_name)\n",
    "                df_gene_cnv = pd.concat([df_gene_cnv, df]).reset_index(drop=True)\n",
    "            except:\n",
    "                # print(sam)\n",
    "                continue\n",
    "    elif disease == \"mgus\":\n",
    "        for sam in all_mgus:\n",
    "            try:\n",
    "                # read sample CNVs\n",
    "                df = read_sam_cnvs(sam, disease)\n",
    "                # Filter CNV for a given gene\n",
    "                df = filter_sam_cnvs(df, gene_name)\n",
    "                df_gene_cnv = pd.concat([df_gene_cnv, df]).reset_index(drop=True)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "    return df_gene_cnv, df_gene_cnv[\"sample\"].unique().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = read_sam_cnvs(\"MMRF_1814_1\", \"mm\")\n",
    "# print(df.shape)\n",
    "# # filter_sam_cnvs(df, \"RYR2\")\n",
    "# string = df.iloc[0][\"gene\"]\n",
    "# genes = sorted(list(set(ast.literal_eval(string))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a,b = all_samp_gene_cnv(\"RYR2\",\"mm\")\n",
    "# a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5631/5631 [00:00<00:00, 27761.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>SvType</th>\n",
       "      <th>CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>END</th>\n",
       "      <th>Gap</th>\n",
       "      <th>sv_gene</th>\n",
       "      <th>genes500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMRF_1020_3_BM</td>\n",
       "      <td>PossibleLargeIndel</td>\n",
       "      <td>5</td>\n",
       "      <td>81571000</td>\n",
       "      <td>98107800</td>\n",
       "      <td>16536800</td>\n",
       "      <td>RGMB,RPS23</td>\n",
       "      <td>RGMB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMRF_1020_3_BM</td>\n",
       "      <td>PossibleLargeIndel</td>\n",
       "      <td>5</td>\n",
       "      <td>81573800</td>\n",
       "      <td>98109200</td>\n",
       "      <td>16535400</td>\n",
       "      <td>RGMB,,RPS23</td>\n",
       "      <td>RGMB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MMRF_1020_3_BM</td>\n",
       "      <td>PossibleLargeIndel</td>\n",
       "      <td>14</td>\n",
       "      <td>65566200</td>\n",
       "      <td>65592800</td>\n",
       "      <td>26600</td>\n",
       "      <td>MAX</td>\n",
       "      <td>MAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MMRF_1020_3_BM</td>\n",
       "      <td>PossibleLargeIndel</td>\n",
       "      <td>14</td>\n",
       "      <td>65569000</td>\n",
       "      <td>65594200</td>\n",
       "      <td>25200</td>\n",
       "      <td>MAX</td>\n",
       "      <td>MAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MMRF_1020_3_BM</td>\n",
       "      <td>PossibleLargeIndel</td>\n",
       "      <td>14</td>\n",
       "      <td>103230400</td>\n",
       "      <td>103359200</td>\n",
       "      <td>128800</td>\n",
       "      <td>TRAF3</td>\n",
       "      <td>TRAF3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SAMPLE              SvType CHROM        POS        END       Gap  \\\n",
       "0  MMRF_1020_3_BM  PossibleLargeIndel     5   81571000   98107800  16536800   \n",
       "1  MMRF_1020_3_BM  PossibleLargeIndel     5   81573800   98109200  16535400   \n",
       "2  MMRF_1020_3_BM  PossibleLargeIndel    14   65566200   65592800     26600   \n",
       "3  MMRF_1020_3_BM  PossibleLargeIndel    14   65569000   65594200     25200   \n",
       "4  MMRF_1020_3_BM  PossibleLargeIndel    14  103230400  103359200    128800   \n",
       "\n",
       "       sv_gene genes500  \n",
       "0   RGMB,RPS23     RGMB  \n",
       "1  RGMB,,RPS23     RGMB  \n",
       "2          MAX      MAX  \n",
       "3          MAX      MAX  \n",
       "4        TRAF3    TRAF3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgen_df1 = pd.read_csv(\"/home/vivek/jupyter_notebooks/bio_dgi_extension/SV_literature/mmrf_sv_filtered/mmrf_tgen_filtered500.txt\", sep='\\t')        \n",
    "tgen_df1[\"sv_gene\"] = [','.join(set((i+','+j+','+k+','+l+','+m+','+n+','+o).replace('.,','').replace('.','').split(','))) for i,j,k,l,m,n,o in zip(tgen_df1[\"gene\"].tolist(), tgen_df1[\"GeneInternalBreak1\"].tolist(), tgen_df1[\"GeneInternalBreak2\"].tolist(), tgen_df1[\"GeneUpstreamBreak1\"].tolist(), tgen_df1[\"GeneUpstreamBreak2\"].tolist(), tgen_df1[\"GeneDownstreamBreak1\"].tolist(), tgen_df1[\"GeneDownstreamBreak2\"].tolist())]\n",
    "\n",
    "# Define function to remove trailing comma from a string\n",
    "def remove_trailing_comma(s):\n",
    "    return s[:-1] if s.endswith(',') else s\n",
    "\n",
    "def remove_start_comma(s):\n",
    "    return s[1:] if s.startswith(',') else s\n",
    "\n",
    "# Apply function to the \"sv_gene\" column and update the DataFrame\n",
    "tgen_df1[\"sv_gene\"] = tgen_df1[\"sv_gene\"].apply(remove_trailing_comma).apply(remove_start_comma)\n",
    "\n",
    "tgen_df1 = tgen_df1[[\"SAMPLE\", \"SvType\", \"CHROM\", \"POS\", \"END\", \"Gap\", \"sv_gene\"]]\n",
    "sv_genes = []\n",
    "for idx in tqdm(range(tgen_df1.shape[0])):\n",
    "    sam_gene = []\n",
    "    for gen in tgen_df1.iloc[idx,-1].split(','):\n",
    "        if gen in top500genes:\n",
    "            sam_gene.append(gen)\n",
    "            \n",
    "    if len(sam_gene) > 1:\n",
    "        sv_genes.append(sam_gene)\n",
    "    else:\n",
    "        sv_genes.append(sam_gene[0])\n",
    "tgen_df1['genes500'] = sv_genes\n",
    "\n",
    "delly_tf1 = pd.read_csv(\"/home/vivek/jupyter_notebooks/bio_dgi_extension/SV_literature/mmrf_sv_filtered/mmrf_delly_filtered500.txt\", sep='\\t')\n",
    "delly_tf1[\"sv_gene\"] = [','.join(set((i+','+j+','+k+','+l+','+m).replace('.,','').split(','))) for i,j,k,l,m in zip(delly_tf1[\"RGENUPS_HUGO\"].tolist(), delly_tf1[\"RGENDNS_HUGO\"].tolist(), delly_tf1[\"LGENUPS_HUGO\"].tolist(),delly_tf1[\"LGENISEC_HUGO\"].tolist(),delly_tf1[\"LGENDNS_HUGO\"].tolist())]\n",
    "delly_tf1 = delly_tf1[[\"Specimen_ID\", \"SVTYPE\", \"CHROM\", \"POS\", \"ENDPOSSV\", \"sv_gene\"]]\n",
    "mmrf_delly_genes500 = []\n",
    "for idx in range(delly_tf1.shape[0]):\n",
    "    gs = delly_tf1.iloc[idx,-1].split(',')\n",
    "    gsn = [i for i in gs if i in top500genes]\n",
    "    mmrf_delly_genes500.append(','.join(gsn))\n",
    "    \n",
    "delly_tf1['genes500'] = mmrf_delly_genes500\n",
    "delly_tf1[\"Gap\"] = [i-j for i,j in zip(delly_tf1[\"ENDPOSSV\"].tolist(), delly_tf1[\"POS\"].tolist())]\n",
    "delly_tf1 = delly_tf1.rename({'Specimen_ID': 'SAMPLE', 'SVTYPE': 'SvType','ENDPOSSV':'END'}, axis=1)\n",
    "delly_tf1 = delly_tf1[['SAMPLE', 'SvType', 'CHROM', 'POS', 'END', 'Gap','sv_gene', 'genes500']]\n",
    "\n",
    "sv_combined = pd.concat([tgen_df1, delly_tf1])\n",
    "sv_combined[\"END\"] = [int(i.split(':')[-1]) if isinstance(i, str) else int(i) for i in sv_combined[\"END\"].values.tolist()]\n",
    "sv_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PossibleInversion': 4535, 'INV': 793, 'DEL': 768, 'TRA': 573, 'PossibleLargeIndel': 535, 'Translocation': 530, 'DUP': 523, 'PossibleTandemDup': 31}\n"
     ]
    }
   ],
   "source": [
    "sdict = sv_combined[\"SvType\"].value_counts().to_dict()\n",
    "print(sdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_gene_svs(df_svs, gene_name):\n",
    "    df_svs = df_svs.query('genes500 == @gene_name').reset_index(drop=True)\n",
    "    return df_svs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snv_top_features(gen_name, disease):\n",
    "    phylop_median_val, synsnv_total, otherssnv_total, nonsynsnv_total, vaf_nonsyn_snvs, vaf_others_snvs, vaf_syn_snvs = [], [], [], [], [], [], []\n",
    "    syn_totalratio, nonsyn_totalratio, others_totalratio = [], [], []\n",
    "    nonsyn_sample_count = 0\n",
    "    sample_list = all_mm if disease == \"mm\" else all_mgus\n",
    "    for sam in sample_list:\n",
    "        df = pd.read_csv(\"/home/vivek/jupyter_notebooks/bio_dgi_extension/feature_matrix/genes798feature26/\" + sam + \".csv\", index_col=0)\n",
    "        f1 = df[(df.index == gen_name)][\"non_syn_phylop_median\"].values[0]\n",
    "        phylop_median_val.append(f1)\n",
    "        f2 = df[(df.index == gen_name)][\"syn_total\"].values[0]\n",
    "        synsnv_total.append(f2)\n",
    "        f3 = df[(df.index == gen_name)][\"non_syn_total\"].values[0]\n",
    "        nonsynsnv_total.append(f3)\n",
    "        f4 = df[(df.index == gen_name)][\"others_total\"].values[0]\n",
    "        otherssnv_total.append(f4)\n",
    "        # f4 = df[(df.index == gen_name)][\"syn_dp_median\"].values[0]\n",
    "        # ad_synsnv_total.append(f4)\n",
    "        f5 = df[(df.index == gen_name)][\"non_syn_vaf_median\"].values[0]\n",
    "        vaf_nonsyn_snvs.append(f5)\n",
    "        f6 = df[(df.index == gen_name)][\"others_vaf_median\"].values[0]\n",
    "        vaf_others_snvs.append(f6)        \n",
    "        f7 = df[(df.index == gen_name)][\"syn_vaf_median\"].values[0]\n",
    "        vaf_syn_snvs.append(f7)\n",
    "        f8 = f2/(f2+f3+f4)\n",
    "        f9 = f3/(f2+f3+f4)\n",
    "        f10 = f4/(f2+f3+f4)\n",
    "        syn_totalratio.append(f8)\n",
    "        nonsyn_totalratio.append(f9)\n",
    "        others_totalratio.append(f10)\n",
    "        if f3 > 0:\n",
    "            nonsyn_sample_count += 1\n",
    "            \n",
    "        syn_totalratio = [0 if math.isnan(x) else x for x in syn_totalratio]\n",
    "        nonsyn_totalratio = [0 if math.isnan(x) else x for x in nonsyn_totalratio]\n",
    "        others_totalratio = [0 if math.isnan(x) else x for x in others_totalratio]\n",
    "    \n",
    "    snv_feat_dict = {disease + '_phylop_median_val_median' : np.median(phylop_median_val),\n",
    "                     disease + '_synsnv_total_median' : np.median(synsnv_total),\n",
    "                     disease + '_nonsynsnv_total_median' : np.median(nonsynsnv_total),\n",
    "                     disease + '_otherssnv_total_median' : np.median(otherssnv_total),\n",
    "                     disease + '_vaf_nonsyn_snvs_median' : np.median(vaf_nonsyn_snvs),\n",
    "                     disease + '_vaf_syn_snvs_median' : np.median(vaf_syn_snvs),\n",
    "                     disease + '_vaf_others_snvs_median' : np.median(vaf_others_snvs),\n",
    "                     disease + '_syn_totalratio_median' : np.median(syn_totalratio),\n",
    "                     disease + '_nonsyn_totalratio_median' : np.median(nonsyn_totalratio),\n",
    "                     disease + '_others_totalratio_median' : np.median(others_totalratio),\n",
    "                     disease + '_others_totalratio_std' : np.std(others_totalratio),\n",
    "                     disease + '_nonsyn_sample_count' : nonsyn_sample_count}\n",
    "    \n",
    "    return snv_feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snv_features(gen_name):\n",
    "    mm_snvs, mm_snvs_median = get_gene_snvs_all_samples(gen_name, \"mm\")\n",
    "    mgus_snvs, mgus_snvs_median = get_gene_snvs_all_samples(gen_name, \"mgus\")\n",
    "    mm_top_feat_dict = snv_top_features(gen_name, \"mm\")\n",
    "    mgus_top_feat_dict = snv_top_features(gen_name, \"mgus\")\n",
    "    snv_dict = {\"mm_sam\": mm_snvs, \n",
    "                \"mm_snvs_median\": np.median(mm_snvs_median), \n",
    "                \"mgus_sam\": mgus_snvs, \n",
    "                \"mgus_snvs_median\": np.median(mgus_snvs_median),\n",
    "                'mm_top_feat_dict': mm_top_feat_dict,\n",
    "                'mgus_top_feat_dict': mgus_top_feat_dict}\n",
    "    \n",
    "    snv_dict1 = {}\n",
    "    for k,v in snv_dict.items():\n",
    "        if isinstance(v, dict):\n",
    "            for k1,v1 in v.items():\n",
    "                snv_dict1[k1] = v1\n",
    "        else:\n",
    "            snv_dict1[k] = v\n",
    "    return snv_dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnv_features(gen_name):\n",
    "    mm_cnvs, mm_sam = all_samp_gene_cnv(gen_name, \"mm\")\n",
    "    if mm_cnvs.shape[0] > 0:\n",
    "        mm_cnvs_del = mm_cnvs[mm_cnvs[\"cn\"] == 0][\"sample\"].unique().shape[0]\n",
    "        mm_cnvs_loss = mm_cnvs[mm_cnvs[\"cn\"] == 1][\"sample\"].unique().shape[0]\n",
    "        mm_cnvs_gain = mm_cnvs[mm_cnvs[\"cn\"] == 3][\"sample\"].unique().shape[0]\n",
    "        mm_cnvs_amp = mm_cnvs[mm_cnvs[\"cn\"] > 3][\"sample\"].unique().shape[0]\n",
    "        common_end = min(mm_cnvs[\"end\"])\n",
    "        common_start = max(mm_cnvs[\"start\"])\n",
    "        common_len = common_end - common_start\n",
    "        if common_len > 0:\n",
    "            mm_cnv_overlap = common_len\n",
    "        else:\n",
    "            mm_cnv_overlap = 0\n",
    "    else:\n",
    "        mm_cnvs_del = 0\n",
    "        mm_cnvs_loss = 0\n",
    "        mm_cnvs_gain = 0\n",
    "        mm_cnvs_amp = 0\n",
    "        mm_cnv_overlap = 0\n",
    "        \n",
    "    mgus_cnvs, mgus_sam = all_samp_gene_cnv(gen_name, \"mgus\")\n",
    "    if mgus_cnvs.shape[0] > 0:\n",
    "        mgus_cnvs_del = mgus_cnvs[mgus_cnvs[\"cn\"] == 0][\"sample\"].unique().shape[0]\n",
    "        mgus_cnvs_loss = mgus_cnvs[mgus_cnvs[\"cn\"] == 1][\"sample\"].unique().shape[0]\n",
    "        mgus_cnvs_gain = mgus_cnvs[mgus_cnvs[\"cn\"] == 3][\"sample\"].unique().shape[0]\n",
    "        mgus_cnvs_amp = mgus_cnvs[mgus_cnvs[\"cn\"] > 3][\"sample\"].unique().shape[0]\n",
    "        common_end = min(mgus_cnvs[\"end\"])\n",
    "        common_start = max(mgus_cnvs[\"start\"])\n",
    "        common_len = common_end - common_start\n",
    "        if common_len > 0:\n",
    "            mgus_cnv_overlap = common_len\n",
    "        else:\n",
    "            mgus_cnv_overlap = 0\n",
    "    else:\n",
    "        mgus_cnvs_del = 0\n",
    "        mgus_cnvs_loss = 0\n",
    "        mgus_cnvs_gain = 0\n",
    "        mgus_cnvs_amp = 0\n",
    "        mgus_cnv_overlap = 0\n",
    "    \n",
    "    cnv_dict = {'mm_cnvs': mm_sam, \n",
    "                'mm_cnvs_del': mm_cnvs_del,\n",
    "                'mm_cnvs_loss': mm_cnvs_loss,\n",
    "                'mm_cnvs_gain': mm_cnvs_gain,\n",
    "                'mm_cnvs_amp': mm_cnvs_amp,\n",
    "                'mm_cnv_overlap': mm_cnv_overlap,\n",
    "                'mgus_cnvs': mgus_sam,\n",
    "                'mgus_cnvs_del': mgus_cnvs_del,\n",
    "                'mgus_cnvs_loss': mgus_cnvs_loss,\n",
    "                'mgus_cnvs_gain': mgus_cnvs_gain,\n",
    "                'mgus_cnvs_amp': mgus_cnvs_amp,\n",
    "                'mgus_cnv_overlap': mgus_cnv_overlap}\n",
    "    \n",
    "    return cnv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sv_features(gen_name):\n",
    "    df_svs = filter_gene_svs(sv_combined, gen_name)\n",
    "    sv_dict = df_svs[\"SvType\"].value_counts().to_dict()\n",
    "    sv_dict['total_svs'] = df_svs.shape[0]\n",
    "    \n",
    "    if 'PossibleInversion' in sv_dict.keys() and 'INV' in sv_dict.keys():\n",
    "        sv_dict['INV'] += sv_dict['PossibleInversion']\n",
    "        del sv_dict['PossibleInversion']\n",
    "    elif 'PossibleInversion' in sv_dict.keys() and 'INV' not in sv_dict.keys():\n",
    "        sv_dict['INV'] = sv_dict['PossibleInversion']\n",
    "        del sv_dict['PossibleInversion']\n",
    "        \n",
    "    if 'TRA' in sv_dict.keys() and 'Translocation' in sv_dict.keys():\n",
    "        sv_dict['TRA'] += sv_dict['Translocation']\n",
    "        del sv_dict['Translocation']\n",
    "    elif 'Translocation' in sv_dict.keys() and 'TRA' not in sv_dict.keys():\n",
    "        sv_dict['TRA'] = sv_dict['Translocation']\n",
    "        del sv_dict['Translocation']\n",
    "        \n",
    "    if 'DUP' in sv_dict.keys() and 'PossibleTandemDup' in sv_dict.keys():\n",
    "        sv_dict['DUP'] += sv_dict['PossibleTandemDup']\n",
    "        del sv_dict['PossibleTandemDup']\n",
    "    elif 'PossibleTandemDup' in sv_dict.keys() and 'DUP' not in sv_dict.keys():\n",
    "        sv_dict['DUP'] = sv_dict['PossibleTandemDup']\n",
    "        del sv_dict['PossibleTandemDup']\n",
    "        \n",
    "    sv_dict1 = {}\n",
    "    sv_dict1[\"total_svs\"] = sv_dict[\"total_svs\"]\n",
    "    sv_dict1[\"INV\"] = sv_dict[\"INV\"] if \"INV\" in sv_dict.keys() else 0\n",
    "    sv_dict1[\"DUP\"] = sv_dict[\"DUP\"] if \"DUP\" in sv_dict.keys() else 0\n",
    "    sv_dict1[\"TRA\"] = sv_dict[\"TRA\"] if \"TRA\" in sv_dict.keys() else 0\n",
    "    sv_dict1[\"PossibleLargeIndel\"] = sv_dict[\"PossibleLargeIndel\"] if \"PossibleLargeIndel\" in sv_dict.keys() else 0\n",
    "    sv_dict1[\"DEL\"] = sv_dict[\"DEL\"] if \"DEL\" in sv_dict.keys() else 0\n",
    "    \n",
    "    return sv_dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lof_hap_features(gen_name):\n",
    "    df = gene_variants[gene_variants['gene_name'] == gen_name]\n",
    "    lof_hap_dict = {'mm_lof':df[\"lof_mm\"].values[0],\n",
    "                    'mgus_lof': df[\"lof_mgus\"].values[0],\n",
    "                    'ghis_score': df[\"ghis_score\"].values[0],\n",
    "                    'rank': df[\"rank\"].values[0]\n",
    "                    }    \n",
    "    return lof_hap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pathway(gen):\n",
    "    pathways = []\n",
    "    if gen in antigen_pathway:\n",
    "        pathways.append(\"antigen presentation pathway\")\n",
    "    if gen in cyto_pathway:\n",
    "        pathways.append(\"cytoskeleton-rearrangement pathway\")\n",
    "    if gen in histone_pathway:\n",
    "        pathways.append(\"histone modification pathway\")\n",
    "    if gen in myeloid_pathway:\n",
    "        pathways.append(\"myeloid-checkpoints\")\n",
    "    if gen in nk_pathway:\n",
    "        pathways.append(\"NK-cell pathway\")\n",
    "        \n",
    "    return pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_df = pd.DataFrame()\n",
    "# genelist = top500genes[:250]\n",
    "# rank, sv_chr, cnv_chr = [], [], []\n",
    "\n",
    "# for gen in tqdm(genelist):\n",
    "#     rank.append(top500genes.index(gen)+1)\n",
    "#     try:\n",
    "#         sv_chr.append(filter_gene_svs(sv_combined,gen).loc[0][\"CHROM\"])\n",
    "#     except:\n",
    "#         sv_chr.append(\"NA\")\n",
    "        \n",
    "#     try:\n",
    "#         df,_ = all_samp_gene_cnv(gen, \"mm\")\n",
    "#         cnv_chr.append(df.loc[0][\"chromosome\"])\n",
    "#     except:\n",
    "#         try:\n",
    "#             df,_ = all_samp_gene_cnv(gen, \"mgus\")\n",
    "#             cnv_chr.append(df.loc[0][\"chromosome\"])\n",
    "#         except:\n",
    "#             cnv_chr.append(\"NA\")\n",
    "    \n",
    "# gene_df[\"gene\"] = genelist\n",
    "# gene_df[\"rank\"] = rank\n",
    "# gene_df[\"sv_chr\"] = sv_chr\n",
    "# gene_df[\"cnv_chr\"] = cnv_chr\n",
    "# gene_df.to_excel(\"gne_cnv_sv_location.xlsx\", index=False)\n",
    "# gene_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_loc(gen):\n",
    "    try:\n",
    "        sv_chr = filter_gene_svs(sv_combined,gen).loc[0][\"CHROM\"]\n",
    "    except:\n",
    "        sv_chr = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        df,_ = all_samp_gene_cnv(gen, \"mm\")\n",
    "        cnv_chr = df.loc[0][\"chromosome\"]\n",
    "    except:\n",
    "        try:\n",
    "            df,_ = all_samp_gene_cnv(gen, \"mgus\")\n",
    "            cnv_chr = df.loc[0][\"chromosome\"]\n",
    "        except:\n",
    "            cnv_chr = \"NA\"\n",
    "            \n",
    "    gene_chr = {\"chr_location\": cnv_chr if cnv_chr != \"NA\" else sv_chr}\n",
    "    # gene_chr = {\"sv_chr\": sv_chr, \"cnv_chr\": cnv_chr}\n",
    "    return gene_chr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver_source(gen):\n",
    "    # driver_dict = {}\n",
    "    # driver_dict[\"intogen\"] = 1 if gen in driver_list1 else 0\n",
    "    # driver_dict[\"list_of_63_driver_genes\"] = 1 if gen in driver_list2 else 0\n",
    "    # driver_dict[\"Genomic_landscape_and_chronological_reconstruction_of_driver_events_in_multiple\"] = 1 if gen in driver_list3 else 0\n",
    "    \n",
    "    driver_list = []\n",
    "    if gen in driver_list1:\n",
    "        driver_list.append(1)\n",
    "    else:\n",
    "        driver_list.append(0)\n",
    "        \n",
    "    if gen in driver_list2:\n",
    "        driver_list.append(2)\n",
    "    else:\n",
    "        driver_list.append(0)\n",
    "    if gen in driver_list3:\n",
    "        driver_list.append(3)\n",
    "    else:\n",
    "        driver_list.append(0)\n",
    "        \n",
    "    if gen in driver_list4:\n",
    "        driver_list.append(4)\n",
    "    else:\n",
    "        driver_list.append(0)\n",
    "        \n",
    "    if gen in driver_list5:\n",
    "        driver_list.append(5)\n",
    "    else:\n",
    "        driver_list.append(0)\n",
    "        \n",
    "    if gen in driver_list6:\n",
    "        driver_list.append(6)\n",
    "    else:\n",
    "        driver_list.append(0)\n",
    "        \n",
    "    if gen in driver_list7:\n",
    "        driver_list.append(7)\n",
    "    else:\n",
    "        driver_list.append(0)\n",
    "    \n",
    "    \n",
    "    return driver_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_category(gen):\n",
    "    gene_cat = {}\n",
    "    if gen in cat_a:\n",
    "        gene_cat[\"tran_onco_rej\"] = \"Transformative\"\n",
    "    elif gen in cat_b:\n",
    "        gene_cat[\"tran_onco_rej\"] = \"Rejected\"\n",
    "    elif gen in cat_c:\n",
    "        gene_cat[\"tran_onco_rej\"] = \"Disease_initiating\"\n",
    "        \n",
    "    # gene_cat[\"gene34\"] = 1 if gen in gene34 else 0\n",
    "    # gene_cat[\"gene77\"] = 1 if gen in gene77 else 0\n",
    "    gene_cat[\"top100\"] = 1 if gen in top500genes[:100] else 0\n",
    "    gene_cat[\"top250\"] = 1 if gen in top500genes[:250] else 0\n",
    "    return gene_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_df = pd.DataFrame()\n",
    "gen_comm, gen_katz_score = [], []\n",
    "genelist = gene798\n",
    "pathways = []\n",
    "mm_lit_drivers = []\n",
    "\n",
    "for gen in tqdm(genelist):\n",
    "    snv_dict = get_snv_features(gen)\n",
    "    cnv_dict = get_cnv_features(gen)\n",
    "    sv_dict = get_sv_features(gen)\n",
    "    lof_hap_dict = get_lof_hap_features(gen)\n",
    "    a,b = gene_centrality(gen)\n",
    "    gen_comm.append(a)\n",
    "    gen_katz_score.append(b)\n",
    "    pathways.append(find_pathway(gen))\n",
    "    \n",
    "    df_snv = pd.DataFrame.from_dict(snv_dict, orient='index', columns=[gen]).T\n",
    "    df_cnv = pd.DataFrame.from_dict(cnv_dict, orient='index', columns=[gen]).T\n",
    "    df_sv = pd.DataFrame.from_dict(sv_dict, orient='index', columns=[gen]).T\n",
    "    df_lof = pd.DataFrame.from_dict(lof_hap_dict, orient='index', columns=[gen]).T\n",
    "    # df_driver = pd.DataFrame.from_dict(driver_source(gen), orient='index', columns=[gen]).T\n",
    "    mm_lit_drivers.append(driver_source(gen))\n",
    "    df_gene_chr = pd.DataFrame.from_dict(gene_loc(gen), orient='index', columns=[gen]).T\n",
    "    df_gene_cat = pd.DataFrame.from_dict(gene_category(gen), orient='index', columns=[gen]).T\n",
    "    df_gene_only = pd.concat([df_snv, df_cnv, df_sv, df_lof, df_gene_chr, df_gene_cat], axis=1)\n",
    "    gene_df = pd.concat([gene_df, df_gene_only])\n",
    "    \n",
    "gene_df['pathways'] = pathways\n",
    "gene_df['mm_driver'] = mm_lit_drivers\n",
    "# gene_df['rank'] = [int(top500genes.index(gen)+1) for gen in genelist]\n",
    "gene_df['gen_comm'] = gen_comm\n",
    "gene_df['gen_katz_score'] = gen_katz_score\n",
    "gene_df.to_excel(\"../gene798_features.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/798 [08:21<15:40:54, 71.37s/it]"
     ]
    }
   ],
   "source": [
    "gene_df = pd.DataFrame()\n",
    "\n",
    "for gen in tqdm(gene798):\n",
    "    \n",
    "    cnv_dict = get_cnv_features(gen)\n",
    "    df_cnv = pd.DataFrame.from_dict(cnv_dict, orient='index', columns=[gen]).T\n",
    "    gene_df = pd.concat([gene_df, df_cnv])\n",
    "    \n",
    "gene_df.to_excel(\"../gene798_cnv_features.xlsx\", index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging of all batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(798, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mm_sam</th>\n",
       "      <th>mm_snvs_median</th>\n",
       "      <th>mgus_sam</th>\n",
       "      <th>mgus_snvs_median</th>\n",
       "      <th>mm_phylop_median_val_median</th>\n",
       "      <th>mm_synsnv_total_median</th>\n",
       "      <th>mm_nonsynsnv_total_median</th>\n",
       "      <th>mm_otherssnv_total_median</th>\n",
       "      <th>mm_vaf_nonsyn_snvs_median</th>\n",
       "      <th>mm_vaf_syn_snvs_median</th>\n",
       "      <th>...</th>\n",
       "      <th>ghis_score</th>\n",
       "      <th>rank</th>\n",
       "      <th>chr_location</th>\n",
       "      <th>tran_onco_rej</th>\n",
       "      <th>top100</th>\n",
       "      <th>top250</th>\n",
       "      <th>pathways</th>\n",
       "      <th>mm_driver</th>\n",
       "      <th>gen_comm</th>\n",
       "      <th>gen_katz_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABCA1</th>\n",
       "      <td>1001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459994</td>\n",
       "      <td>65</td>\n",
       "      <td>chr9</td>\n",
       "      <td>Transformative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0.115337</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABCA3</th>\n",
       "      <td>408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488285</td>\n",
       "      <td>332</td>\n",
       "      <td>chr16</td>\n",
       "      <td>Disease_initiating</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABCA7</th>\n",
       "      <td>373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520105</td>\n",
       "      <td>441</td>\n",
       "      <td>chr19</td>\n",
       "      <td>Transformative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0.019731</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABL2</th>\n",
       "      <td>776</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533039</td>\n",
       "      <td>175</td>\n",
       "      <td>chr1</td>\n",
       "      <td>Transformative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0.086526</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACACB</th>\n",
       "      <td>496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565962</td>\n",
       "      <td>339</td>\n",
       "      <td>chr12</td>\n",
       "      <td>Transformative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0.079910</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mm_sam  mm_snvs_median  mgus_sam  mgus_snvs_median  \\\n",
       "ABCA1    1001             3.0        52                 2   \n",
       "ABCA3     408             0.0        27                 0   \n",
       "ABCA7     373             0.0        42                 1   \n",
       "ABL2      776             1.0        30                 0   \n",
       "ACACB     496             0.0        40                 1   \n",
       "\n",
       "       mm_phylop_median_val_median  mm_synsnv_total_median  \\\n",
       "ABCA1                          0.0                       0   \n",
       "ABCA3                          0.0                       0   \n",
       "ABCA7                          0.0                       0   \n",
       "ABL2                           0.0                       0   \n",
       "ACACB                          0.0                       0   \n",
       "\n",
       "       mm_nonsynsnv_total_median  mm_otherssnv_total_median  \\\n",
       "ABCA1                          0                        3.0   \n",
       "ABCA3                          0                        0.0   \n",
       "ABCA7                          0                        0.0   \n",
       "ABL2                           0                        1.0   \n",
       "ACACB                          0                        0.0   \n",
       "\n",
       "       mm_vaf_nonsyn_snvs_median  mm_vaf_syn_snvs_median  ...  ghis_score  \\\n",
       "ABCA1                        0.0                     0.0  ...    0.459994   \n",
       "ABCA3                        0.0                     0.0  ...    0.488285   \n",
       "ABCA7                        0.0                     0.0  ...    0.520105   \n",
       "ABL2                         0.0                     0.0  ...    0.533039   \n",
       "ACACB                        0.0                     0.0  ...    0.565962   \n",
       "\n",
       "       rank  chr_location       tran_onco_rej  top100  top250  pathways  \\\n",
       "ABCA1    65          chr9      Transformative       1       1        []   \n",
       "ABCA3   332         chr16  Disease_initiating       0       0        []   \n",
       "ABCA7   441         chr19      Transformative       0       0        []   \n",
       "ABL2    175          chr1      Transformative       0       1        []   \n",
       "ACACB   339         chr12      Transformative       0       0        []   \n",
       "\n",
       "                   mm_driver  gen_comm  gen_katz_score  \n",
       "ABCA1  [0, 0, 0, 0, 0, 0, 0]  0.115337              C2  \n",
       "ABCA3  [0, 0, 0, 0, 0, 0, 0]       NaN             NaN  \n",
       "ABCA7  [0, 0, 0, 0, 0, 0, 0]  0.019731              C4  \n",
       "ABL2   [0, 0, 0, 0, 0, 0, 0]  0.086526              C2  \n",
       "ACACB  [0, 0, 0, 0, 0, 0, 0]  0.079910              C2  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel(\"gene_features_50.xlsx\", index_col=0)\n",
    "df2 = pd.read_excel(\"gene_features_100.xlsx\", index_col=0)\n",
    "df3 = pd.read_excel(\"gene_features_150.xlsx\", index_col=0)\n",
    "df4 = pd.read_excel(\"gene_features_200.xlsx\", index_col=0)\n",
    "df5 = pd.read_excel(\"gene_features_250.xlsx\", index_col=0)\n",
    "df6 = pd.read_excel(\"gene_features_300.xlsx\", index_col=0)\n",
    "df7 = pd.read_excel(\"gene_features_350.xlsx\", index_col=0)\n",
    "df8 = pd.read_excel(\"gene_features_400.xlsx\", index_col=0)\n",
    "df9 = pd.read_excel(\"gene_features_450.xlsx\", index_col=0)\n",
    "df10 = pd.read_excel(\"gene_features_500.xlsx\", index_col=0)\n",
    "df11 = pd.read_excel(\"gene_features_550.xlsx\", index_col=0)\n",
    "df12 = pd.read_excel(\"gene_features_600.xlsx\", index_col=0)\n",
    "df13 = pd.read_excel(\"gene_features_650.xlsx\", index_col=0)\n",
    "df14 = pd.read_excel(\"gene_features_700.xlsx\", index_col=0)\n",
    "df15 = pd.read_excel(\"gene_features_750.xlsx\", index_col=0)\n",
    "df16 = pd.read_excel(\"gene_features_798.xlsx\", index_col=0)\n",
    "df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14, df15, df16], axis=0)\n",
    "df.to_excel(\"../gene798_features.xlsx\", index=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgtable = pd.read_csv(\"/home/vivek/refs/ucsc_data/hgTables.csv\", header = 0)\n",
    "hgtable_genename = pd.read_csv(\"/home/vivek/refs/ucsc_data/hgTables_gene_name.txt\", sep=\"\\t\", header=0)\n",
    "hgtable_genename = hgtable_genename[hgtable_genename[\"geneSymbol\"].isin(gene798)]\n",
    "\n",
    "def fetch_geneid(s):\n",
    "    return s.split(\";\")[1].split(\" \")[-1].replace('\"', '')\n",
    "\n",
    "def fetch_genename(s):\n",
    "    return hgtable_genename[hgtable_genename[\"#kgID\"] == s][\"geneSymbol\"].values[0]\n",
    "\n",
    "def fetch_transcripts(gene_name):\n",
    "    return hgtable_genename[hgtable_genename[\"geneSymbol\"] == gene_name][\"#kgID\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr12'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgtable[hgtable[\"alignID\"] == fetch_transcripts(\"KRAS\")[0]][\"chrom\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 32/798 [00:00<00:05, 136.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 121/798 [00:00<00:04, 144.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMTR2 []\n",
      "CXorf67 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 452/798 [00:03<00:02, 163.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPIPA5 []\n",
      "NPIPB15 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 503/798 [00:03<00:01, 161.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR8G5 []\n",
      "OR9G1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 552/798 [00:03<00:01, 157.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRAMEF7 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 600/798 [00:04<00:01, 157.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIMBP3B []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 650/798 [00:04<00:00, 161.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPATA31A1 []\n",
      "SUGCT []\n",
      "TBC1D3F []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 751/798 [00:05<00:00, 156.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WASH4P []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 798/798 [00:05<00:00, 147.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>chr_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABCA1</td>\n",
       "      <td>chr9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABCA3</td>\n",
       "      <td>chr16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABCA7</td>\n",
       "      <td>chr19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABL2</td>\n",
       "      <td>chr1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACACB</td>\n",
       "      <td>chr12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gene chr_loc\n",
       "0  ABCA1    chr9\n",
       "1  ABCA3   chr16\n",
       "2  ABCA7   chr19\n",
       "3   ABL2    chr1\n",
       "4  ACACB   chr12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_chr_loc = pd.DataFrame()\n",
    "gene_chr_loc[\"gene\"] = gene798\n",
    "\n",
    "chr_loc = []\n",
    "\n",
    "for gen in tqdm(gene798):\n",
    "    try:\n",
    "        chr_loc.append(hgtable[hgtable[\"alignID\"] == fetch_transcripts(gen)[0]][\"chrom\"].values[0])\n",
    "    except:\n",
    "        print(gen, fetch_transcripts(gen))\n",
    "        chr_loc.append(\"NA\")\n",
    "        \n",
    "gene_chr_loc[\"chr_loc\"] = chr_loc\n",
    "gene_chr_loc.to_excel(\"../gene_chr_loc.xlsx\", index=False)\n",
    "gene_chr_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
